{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4180a076",
   "metadata": {},
   "source": [
    "# Importing necessary libraries for SLM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92ad3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9d4b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, random\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e040c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2adb73",
   "metadata": {},
   "source": [
    "# Root Mean Square Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b6ddf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):  \n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Force float32 for norm calculation to avoid overflow\n",
    "        x_f32 = x.float()\n",
    "        norm = x_f32.pow(2).mean(-1, keepdim=True)\n",
    "        return x * torch.rsqrt(norm + self.eps).type_as(x) * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17541169",
   "metadata": {},
   "source": [
    "# Rotary Positional Embeddings (RoPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e75e6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    x1 = x[..., :x.shape[-1]//2]\n",
    "    x2 = x[..., x.shape[-1]//2:]\n",
    "    return torch.cat([-x2, x1], dim=-1)\n",
    "\n",
    "def apply_rope(x, rope_sin, rope_cos):\n",
    "    return (x * rope_cos) + (rotate_half(x) * rope_sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42455e",
   "metadata": {},
   "source": [
    "# Multi-Head Self Attention (Causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1827d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x, mask, rope_sin, rope_cos):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        qkv = self.qkv(x)  # (B, T, 3*C)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # reshape -> (B, heads, T, head_dim)\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # apply RoPE to q,k\n",
    "        q = apply_rope(q, rope_sin, rope_cos)\n",
    "        k = apply_rope(k, rope_sin, rope_cos)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        att = att.masked_fill(mask == 0, float('-inf'))\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "\n",
    "        y = att @ v  # (B, heads, T, head_dim)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        return self.proj(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3b1ba",
   "metadata": {},
   "source": [
    "# SwiGLU FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec3ac19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(dim, hidden_dim)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w3(torch.nn.functional.silu(self.w1(x)) * self.w2(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f66dc4",
   "metadata": {},
   "source": [
    "# Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a8f1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.attn = MultiHeadSelfAttention(dim, num_heads)\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        self.ffn = SwiGLU(dim, ffn_dim)\n",
    "\n",
    "    def forward(self, x, mask, rope_sin, rope_cos):\n",
    "        x = x + self.attn(self.norm1(x), mask, rope_sin, rope_cos)\n",
    "        x = x + self.ffn(self.norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b0def",
   "metadata": {},
   "source": [
    "# Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fa04b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size, dim, num_layers, num_heads, ffn_dim, max_seq_len=2048):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(dim, num_heads, ffn_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.norm = RMSNorm(dim)\n",
    "        self.lm_head = nn.Linear(dim, vocab_size, bias=False)\n",
    "\n",
    "        # weight tying\n",
    "        self.lm_head.weight = self.token_emb.weight\n",
    "\n",
    "        pos = torch.arange(max_seq_len)  # [T]\n",
    "        freqs = 1.0 / (10000 ** (torch.arange(0, self.head_dim, 2) / self.head_dim))\n",
    "        # freqs len = head_dim/2\n",
    "\n",
    "        sinusoid = torch.einsum(\"i,j->ij\", pos, freqs)  # [T, head_dim/2]\n",
    "\n",
    "        rope_sin = sinusoid.sin()   # [T, head_dim/2]\n",
    "        rope_cos = sinusoid.cos()   # [T, head_dim/2]\n",
    "\n",
    "        # Expand to: [1, 1, T, head_dim]\n",
    "        rope_sin = torch.cat([rope_sin, rope_sin], dim=-1)\n",
    "        rope_cos = torch.cat([rope_cos, rope_cos], dim=-1)\n",
    "\n",
    "        self.register_buffer(\"rope_sin\", rope_sin.unsqueeze(0).unsqueeze(0))\n",
    "        self.register_buffer(\"rope_cos\", rope_cos.unsqueeze(0).unsqueeze(0))\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, mask):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        x = self.token_emb(idx)\n",
    "\n",
    "        # Correct slice: [1,1,T,head_dim]\n",
    "        rope_sin = self.rope_sin[:, :, :T, :]\n",
    "        rope_cos = self.rope_cos[:, :, :T, :]\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, mask, rope_sin, rope_cos)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ed9206",
   "metadata": {},
   "source": [
    "# Causal Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b6c323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(T, device):\n",
    "    m = torch.tril(torch.ones((T, T), dtype=torch.bool, device=device))\n",
    "    return m.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebade2",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1fc12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PackedLMDataset(Dataset):\n",
    "    def __init__(self, file, tokenizer, seq_len=128):\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "    \n",
    "        self.eos_id = tokenizer.token_to_id(\"</s>\")\n",
    "        if self.eos_id is None:\n",
    "            self.eos_id = tokenizer.token_to_id(\"<|endoftext|>\")\n",
    "        \n",
    "        if self.eos_id is None:\n",
    "            print(\"WARNING: No EOS token found! Defaulting to ID 0. Please check tokenizer.\")\n",
    "            self.eos_id = 0\n",
    "\n",
    "        buffer = []\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                text = line.strip()\n",
    "                if len(text) < 2: continue \n",
    "\n",
    "                ids = tokenizer.encode(text).ids\n",
    "                buffer.extend(ids)\n",
    "                buffer.append(self.eos_id)\n",
    "\n",
    "        chunk_size = seq_len + 1\n",
    "        total_chunks = len(buffer) // chunk_size\n",
    "        \n",
    "        print(f\"Dataset {file}: Packed {len(buffer)} tokens into {total_chunks} sequences.\")\n",
    "        \n",
    "        for i in range(total_chunks):\n",
    "            start = i * chunk_size\n",
    "            end = start + chunk_size\n",
    "            self.examples.append(buffer[start:end])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.examples[idx]\n",
    "        data = torch.tensor(chunk, dtype=torch.long)\n",
    "        x = data[:-1]\n",
    "        y = data[1:]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67e18f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../prepared\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"lm_train.txt\")\n",
    "VAL_FILE = os.path.join(DATA_DIR, \"lm_val.txt\")\n",
    "TOKENIZER_FILE = \"../tokens/tokenizer.json\"\n",
    "OUTPUT_DIR = \"checkpoints\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "VOCAB_SIZE = 16000\n",
    "DIM = 256\n",
    "NUM_LAYERS = 6\n",
    "NUM_HEADS = 8\n",
    "FFN_DIM = 1024\n",
    "MAX_SEQ_LEN = 512\n",
    "\n",
    "SEQ_LEN = 512\n",
    "PHYSICAL_BATCH = 1\n",
    "GRAD_ACCUM_STEPS = 32\n",
    "EPOCHS = 15\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_EVERY_STEPS = 2000\n",
    "VAL_EVERY_STEPS = 2000\n",
    "LOG_EVERY = 50\n",
    "USE_AMP = True\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc31a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25c8e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Devices: 1\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Devices:\", torch.cuda.device_count())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0fdafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(step, model, optimizer, scaler=None):\n",
    "    ckpt = {\n",
    "        \"step\": step,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "    }\n",
    "    if scaler is not None:\n",
    "        ckpt[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "    fname = os.path.join(OUTPUT_DIR, f\"ckpt_step_{step}.pt\")\n",
    "    torch.save(ckpt, fname)\n",
    "    print(\"Saved checkpoint:\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f304fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Dataset ../prepared\\lm_train.txt: Packed 8847968 tokens into 17247 sequences.\n",
      "Dataset ../prepared\\lm_val.txt: Packed 456854 tokens into 890 sequences.\n",
      "Creating model...\n",
      "Param count (M): 10.410752\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tok = Tokenizer.from_file(TOKENIZER_FILE)\n",
    "\n",
    "train_ds = PackedLMDataset(TRAIN_FILE, tok, seq_len=SEQ_LEN)\n",
    "val_ds = PackedLMDataset(VAL_FILE, tok, seq_len=SEQ_LEN)\n",
    "train_loader = DataLoader(train_ds, batch_size=PHYSICAL_BATCH, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=PHYSICAL_BATCH, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n",
    "\n",
    "print(\"Creating model...\")\n",
    "model = TransformerLM(VOCAB_SIZE, DIM, NUM_LAYERS, NUM_HEADS, FFN_DIM, max_seq_len=MAX_SEQ_LEN).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "print(\"Param count (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(USE_AMP and device.type==\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0602b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, device, max_batches=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(val_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        T = x.size(1)\n",
    "        mask = causal_mask(T, device)\n",
    "        logits = model(x, mask)\n",
    "\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            y.view(-1)\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n += 1\n",
    "        if max_batches and n >= max_batches:\n",
    "            break\n",
    "\n",
    "    model.train()\n",
    "    return total_loss / max(1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15ab4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(ckpt_path, model, optimizer, scaler=None, device=\"cuda\"):\n",
    "    print(f\"Loading checkpoint from {ckpt_path} ...\")\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    if scaler and \"scaler_state_dict\" in checkpoint:\n",
    "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "\n",
    "    step = checkpoint.get(\"step\", 0)\n",
    "    print(f\"Checkpoint loaded. Resuming from step {step}\")\n",
    "    return step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cff694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training from step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 17247/17247 [46:38<00:00,  6.16it/s, inst_loss=3.437768, avg_epoch=6.209408, grad=1.428424, lr=0.000299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done | loss 6.022870 | time 2798.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 17247/17247 [46:37<00:00,  6.17it/s, inst_loss=3.413316, avg_epoch=2.999848, grad=1.050429, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 done | loss 2.981179 | time 2797.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 17247/17247 [46:37<00:00,  6.16it/s, inst_loss=3.065455, avg_epoch=2.461367, grad=1.020763, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 done | loss 2.458145 | time 2797.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  72%|███████▏  | 12352/17247 [33:25<57:07,  1.43it/s, inst_loss=2.485291, avg_epoch=2.224422, grad=1.181633, lr=0.000300]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] step 2000 | loss 2.291374\n",
      "Saved checkpoint: checkpoints\\ckpt_step_2000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 17247/17247 [46:40<00:00,  6.16it/s, inst_loss=1.901951, avg_epoch=2.210123, grad=1.092904, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 done | loss 2.210049 | time 2800.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 17247/17247 [46:24<00:00,  6.19it/s, inst_loss=0.947873, avg_epoch=2.041641, grad=1.132612, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 done | loss 2.039837 | time 2784.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 17247/17247 [46:37<00:00,  6.16it/s, inst_loss=2.103732, avg_epoch=1.906870, grad=1.140923, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 done | loss 1.906873 | time 2797.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 17247/17247 [46:35<00:00,  6.17it/s, inst_loss=1.494647, avg_epoch=1.797836, grad=1.231954, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 done | loss 1.797819 | time 2795.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  43%|████▎     | 7488/17247 [20:16<1:51:53,  1.45it/s, inst_loss=1.337981, avg_epoch=1.686850, grad=1.296434, lr=0.000300]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] step 4000 | loss 2.043457\n",
      "Saved checkpoint: checkpoints\\ckpt_step_4000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 17247/17247 [46:40<00:00,  6.16it/s, inst_loss=1.461035, avg_epoch=1.706231, grad=1.238158, lr=0.000300] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 done | loss 1.706555 | time 2800.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 17247/17247 [46:39<00:00,  6.16it/s, inst_loss=1.256974, avg_epoch=1.628789, grad=1.267757, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 done | loss 1.628502 | time 2799.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 17247/17247 [46:38<00:00,  6.16it/s, inst_loss=1.962602, avg_epoch=1.558166, grad=1.324396, lr=0.000300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 done | loss 1.561295 | time 2798.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 17247/17247 [46:39<00:00,  6.16it/s, inst_loss=1.474430, avg_epoch=1.501053, grad=1.378304, lr=0.000299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 done | loss 1.501828 | time 2799.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  15%|█▌        | 2624/17247 [07:07<2:48:07,  1.45it/s, inst_loss=0.814274, avg_epoch=1.395229, grad=1.415693, lr=0.000299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] step 6000 | loss 1.997204\n",
      "Saved checkpoint: checkpoints\\ckpt_step_6000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 17247/17247 [46:41<00:00,  6.16it/s, inst_loss=1.070801, avg_epoch=1.448779, grad=1.493665, lr=0.000299] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 done | loss 1.449855 | time 2801.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 17247/17247 [46:35<00:00,  6.17it/s, inst_loss=1.454180, avg_epoch=1.399046, grad=1.478283, lr=0.000299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 done | loss 1.403319 | time 2795.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 17247/17247 [46:30<00:00,  6.18it/s, inst_loss=1.429631, avg_epoch=1.358742, grad=1.419133, lr=0.000299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 done | loss 1.360885 | time 2790.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15:  87%|████████▋ | 14976/17247 [40:20<26:35,  1.42it/s, inst_loss=1.706369, avg_epoch=1.316011, grad=1.549766, lr=0.000299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] step 8000 | loss 1.984653\n",
      "Saved checkpoint: checkpoints\\ckpt_step_8000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 17247/17247 [46:26<00:00,  6.19it/s, inst_loss=1.606475, avg_epoch=1.320162, grad=1.534188, lr=0.000299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 done | loss 1.323051 | time 2786.79s\n",
      "Saved checkpoint: checkpoints\\ckpt_step_8070.pt\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_lr(step, warmup_steps=500, max_lr=LR, min_lr=1e-6, total_steps=200000):\n",
    "    if step < warmup_steps:\n",
    "        return max_lr * step / warmup_steps\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    return min_lr + cosine_decay * (max_lr - min_lr)\n",
    "\n",
    "\n",
    "resume_from = None\n",
    "\n",
    "if resume_from:\n",
    "    global_step = load_checkpoint(resume_from, model, optimizer, scaler, device=device)\n",
    "else:\n",
    "    global_step = 0\n",
    "\n",
    "model.train()\n",
    "print(f\"Begin training from step {global_step}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    epoch_loss_sum = 0.0\n",
    "    epoch_token_count = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch_idx, (x, y) in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        T = x.size(1)\n",
    "        mask = causal_mask(T, device)\n",
    "\n",
    "        lr_now = get_lr(global_step)\n",
    "        optimizer.param_groups[0][\"lr\"] = lr_now\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
    "            logits = model(x, mask)\n",
    "            loss_full = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "\n",
    "        instant_loss = loss_full.item()\n",
    "        epoch_loss_sum += instant_loss * x.numel()\n",
    "        epoch_token_count += x.numel()\n",
    "\n",
    "        loss = loss_full / GRAD_ACCUM_STEPS\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0).item()\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            global_step += 1\n",
    "            avg_epoch_loss = epoch_loss_sum / epoch_token_count\n",
    "\n",
    "            if global_step % LOG_EVERY == 0:\n",
    "                pbar.set_postfix({\n",
    "                    \"inst_loss\": f\"{instant_loss:.6f}\",\n",
    "                    \"avg_epoch\": f\"{avg_epoch_loss:.6f}\",\n",
    "                    \"grad\": f\"{grad_norm:.6f}\",\n",
    "                    \"lr\": f\"{lr_now:.6f}\"\n",
    "                })\n",
    "\n",
    "            if global_step % VAL_EVERY_STEPS == 0:\n",
    "                val_loss = evaluate(model, val_loader, device, max_batches=100)\n",
    "                print(f\"[VAL] step {global_step} | loss {val_loss:.6f}\")\n",
    "                save_checkpoint(global_step, model, optimizer, scaler)\n",
    "\n",
    "            elif global_step % SAVE_EVERY_STEPS == 0:\n",
    "                save_checkpoint(global_step, model, optimizer, scaler)\n",
    "\n",
    "    epoch_loss_final = epoch_loss_sum / epoch_token_count\n",
    "    print(f\"Epoch {epoch+1} done | loss {epoch_loss_final:.6f} | time {time.time() - epoch_start:.2f}s\")\n",
    "\n",
    "save_checkpoint(global_step, model, optimizer, scaler)\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef694a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
